import streamlit as st
import torch
import numpy as np
import cv2
from torchvision.models.detection import ssd300_vgg16
import matplotlib.pyplot as plt
from io import BytesIO

# âœ… ëª¨ë¸ ì •ì˜ í•¨ìˆ˜
def get_ssd_model(num_classes):
    model = ssd300_vgg16(pretrained=False)
    model.head.classification_head.num_classes = num_classes
    return model

# âœ… ëª¨ë¸ íŒŒì¼ ê²½ë¡œ (ë¡œì»¬ì— ì €ìž¥ëœ ëª¨ë¸ íŒŒì¼ ê²½ë¡œë¡œ ë³€ê²½)
model_paths = [
    "best_model_ssd_fold1.pth",
    "best_model_ssd_fold2.pth",
    "best_model_ssd_fold3.pth",
    "best_model_ssd_fold4.pth",
    "best_model_ssd_fold5.pth"
]

# âœ… GPU ì„¤ì • (Streamlitì—ì„œëŠ” CPU ì‚¬ìš©)
device = torch.device("cpu")

# âœ… ëª¨ë¸ ë¡œë“œ í•¨ìˆ˜
def load_model(path, num_classes=5):
    model = get_ssd_model(num_classes).to(device)
    model.load_state_dict(torch.load(path, map_location=device))
    model.eval()
    return model

# âœ… ëª¨ë¸ ë¡œë”© ìºì‹± (í•œë²ˆë§Œ ë¡œë“œí•˜ë„ë¡ ìºì‹±)
@st.cache_resource(show_spinner=False)  # Streamlit 1.18 ì´ìƒ ì‚¬ìš©
def get_models():
    return [load_model(path) for path in model_paths]

# âœ… ì´ë¯¸ì§€ ì „ì²˜ë¦¬ í•¨ìˆ˜
def preprocess_image(image):
    image_resized = cv2.resize(image, (300, 300))
    image_normalized = image_resized / 255.0
    image_transposed = np.transpose(image_normalized, (2, 0, 1))
    return torch.tensor(image_transposed, dtype=torch.float).unsqueeze(0).to(device), image

# âœ… NMS ì ìš© í•¨ìˆ˜
def non_max_suppression(boxes, scores, iou_threshold=0.5):
    indices = torch.ops.torchvision.nms(
        torch.tensor(boxes, dtype=torch.float),
        torch.tensor(scores, dtype=torch.float),
        iou_threshold
    )
    return indices.numpy()

# âœ… ë°”ìš´ë”© ë°•ìŠ¤ í‰ê· í™” í•¨ìˆ˜
def ensemble_boxes_mean(boxes_list, scores_list, labels_list):
    if len(boxes_list) == 0:
        return [], [], []
    
    boxes = np.mean(boxes_list, axis=0)
    scores = np.mean(scores_list, axis=0)
    labels = np.array(labels_list)
    
    return boxes, scores, labels

def ensemble_predictions(image):
    image_tensor, original_image = preprocess_image(image)
    h, w = original_image.shape[:2]

    boxes_list, scores_list, labels_list = [], [], []
    models = get_models()  # ìºì‹±ëœ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°

    # ê° ëª¨ë¸ì˜ ì˜ˆì¸¡ ê²°ê³¼ ìˆ˜ì§‘
    for model in models:
        with torch.no_grad():
            outputs = model(image_tensor)[0]

        boxes = outputs["boxes"].cpu().numpy()   # 300Ã—300 ê¸°ì¤€ ì¢Œí‘œ
        scores = outputs["scores"].cpu().numpy()
        labels = outputs["labels"].cpu().numpy()

        # ê° ëª¨ë¸ì˜ ê²°ê³¼ë¥¼ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€ (extend ëŒ€ì‹  appendë¡œ ê°œë³„ ë°°ì—´ì„ ì €ìž¥í•œ í›„ concatenate)
        boxes_list.append(boxes)
        scores_list.append(scores)
        labels_list.append(labels)

    # ê° ëª¨ë¸ì˜ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ëª¨ë‘ í•©ì¹˜ê¸°
    if len(boxes_list) > 0:
        all_boxes = np.concatenate(boxes_list, axis=0)
        all_scores = np.concatenate(scores_list, axis=0)
        all_labels = np.concatenate(labels_list, axis=0)
    else:
        return original_image

    # NMS ì ìš©
    indices = non_max_suppression(all_boxes.tolist(), all_scores.tolist(), iou_threshold=0.4)
    final_boxes = all_boxes[indices]
    final_scores = all_scores[indices]
    final_labels = all_labels[indices]

    # (ì´ë¯¸ì§€ê°€ 300x300ì´ë¯€ë¡œ ì¢Œí‘œ ë³€í™˜ì€ í•„ìš” ì—†ìŒ)

    # ê²°ê³¼ ì‹œê°í™”
    for box, score, label in zip(final_boxes, final_scores, final_labels):
        x1, y1, x2, y2 = map(int, box)
        # (ì˜µì…˜) ê²½ê³„ë¥¼ ì•½ê°„ í™•ìž¥
        x1, y1, x2, y2 = x1 - 1, y1 - 1, x2 + 1, y2 + 1
        cv2.rectangle(original_image, (x1, y1), (x2, y2), (0, 255, 0), 2)
        
        label_mapping = {1: "Extruded", 2: "Crack", 3: "Cutting", 4: "Side_stamp"}
        label_text = label_mapping.get(int(label), "Unknown")
        cv2.putText(original_image, f"{label_text} {score:.2f}", (x1, y1 - 10),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)

    return original_image


    # NMS ì ìš© (ë¦¬ìŠ¤íŠ¸ê°€ ì•„ë‹Œ np.arrayë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ì—¬ ì‚¬ìš©)
    indices = non_max_suppression(all_boxes.tolist(), all_scores.tolist(), iou_threshold=0.4)

    final_boxes = all_boxes[indices]
    final_scores = all_scores[indices]
    final_labels = all_labels[indices]

    # ë§Œì•½ ë°•ìŠ¤ ì¢Œí‘œê°€ ì •ê·œí™”ëœ ê°’ì´ë¼ë©´ ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸°ë¡œ ë³µì›
    if final_boxes.shape[0] > 0 and final_boxes.max() <= 1.0:
        final_boxes = np.round(final_boxes * [w, h, w, h]).astype(int)
        final_boxes = np.clip(final_boxes, 0, [w-1, h-1, w-1, h-1])
    
    # ê²°ê³¼ ì‹œê°í™”
    for box, score, label in zip(final_boxes, final_scores, final_labels):
        x1, y1, x2, y2 = map(int, box)
        # ê²½ê³„ë¥¼ ì•½ê°„ í™•ìž¥í•´ì„œ í‘œì‹œ
        x1, y1, x2, y2 = x1 - 1, y1 - 1, x2 + 1, y2 + 1
        cv2.rectangle(original_image, (x1, y1), (x2, y2), (0, 255, 0), 2)
        
        label_mapping = {1: "Extruded", 2: "Crack", 3: "Cutting", 4: "Side_stamp"}
        label_text = label_mapping.get(int(label), "Unknown")
        
        cv2.putText(original_image, f"{label_text} {score:.2f}", (x1, y1 - 10),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)

    return original_image


# âœ… Streamlit UI
def main():
    st.title("ðŸ” SSD Object Detection Ensemble")
    st.write("ðŸ’¡ SSD300 VGG16 ëª¨ë¸ ì•™ìƒë¸”ì„ ì‚¬ìš©í•œ ê°ì²´ íƒì§€")
    
    uploaded_file = st.file_uploader("ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”", type=["png", "jpg", "jpeg"])

    if uploaded_file is not None:
        # âœ… ì—…ë¡œë“œëœ ì´ë¯¸ì§€ ì½ê¸°
        file_bytes = np.asarray(bytearray(uploaded_file.read()), dtype=np.uint8)
        image = cv2.imdecode(file_bytes, 1)
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        
        # âœ… ì›ë³¸ ì´ë¯¸ì§€ ì¶œë ¥
        st.image(image, caption="ðŸ“· ì—…ë¡œë“œëœ ì´ë¯¸ì§€", use_container_width=True)
        
        if st.button("ðŸ”Ž íƒì§€ ì‹¤í–‰"):
            with st.spinner("ëª¨ë¸ ì‹¤í–‰ ì¤‘... â³"):
                result_image = ensemble_predictions(image)
                
                # âœ… ê²°ê³¼ ì´ë¯¸ì§€ í‘œì‹œ
                st.image(result_image, caption="ðŸ” íƒì§€ ê²°ê³¼", use_container_width=True)
                
                # âœ… ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ê¸°ëŠ¥ ì¶”ê°€
                img_rgb = cv2.cvtColor(result_image, cv2.COLOR_RGB2BGR)
                is_success, buffer = cv2.imencode(".jpg", img_rgb)
                if is_success:
                    st.download_button(
                        label="ðŸ“¥ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ",
                        data=BytesIO(buffer.tobytes()),
                        file_name="detection_result.jpg",
                        mime="image/jpeg"
                    )

if __name__ == "__main__":
    main()
