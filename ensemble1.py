import torch
from torchvision.models.detection import ssd300_vgg16
import cv2
import numpy as np
from matplotlib import pyplot as plt

# âœ… ëª¨ë¸ ì •ì˜
def get_ssd_model(num_classes):
    model = ssd300_vgg16(pretrained=False)
    model.head.classification_head.num_classes = num_classes
    return model

# ëª¨ë¸ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸ (Google Drive ê²½ë¡œë¡œ ìˆ˜ì •)
model_paths = [
    'best_model_ssd_fold1.pth',
    'best_model_ssd_fold2.pth',
    'best_model_ssd_fold3.pth',
    'best_model_ssd_fold4.pth',
    'best_model_ssd_fold5.pth'
]

# GPU ì‚¬ìš© ì„¤ì • (ì—¬ê¸°ì„œëŠ” CPU ì‚¬ìš©)
device = torch.device('cpu')
print(f"Using device: {device}")

# ëª¨ë¸ ë¡œë“œ í•¨ìˆ˜
def load_model(path, num_classes=6):  # ë°°ê²½ í¬í•¨ ì´ 6 í´ëž˜ìŠ¤
    model = get_ssd_model(num_classes).to(device)
    model.load_state_dict(torch.load(path, map_location=device))
    model.eval()
    return model

# âœ… ëª¨ë¸ ë¡œë”© ìºì‹± (í•œë²ˆë§Œ ë¡œë“œí•˜ë„ë¡ ìºì‹±)
@st.cache_resource(show_spinner=False)  # Streamlit 1.18 ì´ìƒ ì‚¬ìš©
def get_models():
    return [load_model(path) for path in model_paths]

# 5ê°œì˜ ëª¨ë¸ ë¡œë“œ
models = [load_model(path) for path in model_paths]

def preprocess_image(image_path):
    image = cv2.imread(image_path)
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    image_resized = cv2.resize(image, (300, 300))  # SSD300 ìž…ë ¥ í¬ê¸°ì— ë§žì¶¤
    image_normalized = image_resized / 255.0
    image_transposed = np.transpose(image_normalized, (2, 0, 1))
    return torch.tensor(image_transposed, dtype=torch.float).unsqueeze(0).to(device), image

def compute_iou(box1, box2):
    x1 = max(box1[0], box2[0])
    y1 = max(box1[1], box2[1])
    x2 = min(box1[2], box2[2])
    y2 = min(box1[3], box2[3])
    
    inter_area = max(0, x2 - x1 + 1) * max(0, y2 - y1 + 1)
    box1_area = (box1[2] - box1[0] + 1) * (box1[3] - box1[1] + 1)
    box2_area = (box2[2] - box2[0] + 1) * (box2[3] - box2[1] + 1)
    
    iou = inter_area / float(box1_area + box2_area - inter_area)
    return iou

# ê°€ì¤‘ ë‹¤ìˆ˜ê²°ë¡œ í´ëŸ¬ìŠ¤í„° ë‚´ ìµœì¢… ë ˆì´ë¸” ê²°ì • í•¨ìˆ˜
def get_cluster_label(cluster):
    label_scores = {}
    for pred in cluster['preds']:
        label = pred['label']
        score = pred['score']
        label_scores[label] = label_scores.get(label, 0) + score
    best_label = max(label_scores, key=label_scores.get)
    return best_label

def cluster_predictions(predictions, iou_threshold=0.5):
    clusters = []
    predictions_sorted = sorted(predictions, key=lambda x: x['score'], reverse=True)
    
    for pred in predictions_sorted:
        assigned = False
        for cluster in clusters:
            iou_val = compute_iou(pred['box'], cluster['box'])
            if iou_val >= iou_threshold:
                cluster['preds'].append(pred)
                boxes = np.array([p['box'] for p in cluster['preds']])
                cluster['box'] = boxes.mean(axis=0)
                scores = np.array([p['score'] for p in cluster['preds']])
                cluster['score'] = scores.mean()
                cluster['label'] = get_cluster_label(cluster)
                assigned = True
                break
        if not assigned:
            clusters.append({
                'preds': [pred],
                'box': np.array(pred['box']),
                'score': pred['score'],
                'label': pred['label']
            })
    return clusters

def ensemble_predictions(image_path, iou_thr=0.5, score_thr=0.5):
    image_tensor, original_image = preprocess_image(image_path)
    h, w = original_image.shape[:2]

    predictions = []
    for model in models:
        with torch.no_grad():
            outputs = model(image_tensor)[0]
        # score thresholdì™€ í•¨ê»˜ ë°°ê²½(0) ì˜ˆì¸¡ ì œê±°
        valid_idx = (outputs['scores'] > score_thr) & (outputs['labels'] != 0)
        boxes = outputs['boxes'][valid_idx].cpu().numpy()
        scores = outputs['scores'][valid_idx].cpu().numpy()
        labels = outputs['labels'][valid_idx].cpu().numpy()
        
        for box, score, label in zip(boxes, scores, labels):
            predictions.append({
                'box': box,
                'score': score,
                'label': int(label)
            })
    
    if len(predictions) > 0:
        max_box_val = max([np.max(pred['box']) for pred in predictions])
        if max_box_val <= 1.0:
            for pred in predictions:
                pred['box'] = np.array(pred['box']) * np.array([w, h, w, h])
    
    clusters = cluster_predictions(predictions, iou_threshold=iou_thr)
    print(f"ìµœì¢… ê²€ì¶œ ê°ì²´ ìˆ˜: {len(clusters)}")
    
    # ìˆ˜ì •ëœ label mapping (ë°°ê²½ì€ ì œì™¸)
    label_mapping = {
        1: 'normal',
        2: 'Extruded',
        3: 'Crack',
        4: 'Cutting',
        5: 'Side_stamp'
    }
    
    for cluster in clusters:
        box = cluster['box']
        score = cluster['score']
        label = cluster['label']
        box = np.round(box).astype(int)
        x1, y1, x2, y2 = box
        cv2.rectangle(original_image, (x1-1, y1-1), (x2+1, y2+1), (0, 255, 0), 2)
        label_text = label_mapping.get(label, 'Unknown')
        cv2.putText(original_image, f'{label_text} {score:.2f}', (x1, y1 - 10),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)
    
    plt.figure(figsize=(10, 10))
    plt.imshow(original_image)
    plt.axis('off')
    plt.show()



# âœ… Streamlit UI
def main():
    st.title("ðŸ” SSD Object Detection Ensemble")
    st.write("ðŸ’¡ SSD300 VGG16 ëª¨ë¸ ì•™ìƒë¸”ì„ ì‚¬ìš©í•œ ê°ì²´ íƒì§€")
    
    uploaded_file = st.file_uploader("ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”", type=["png", "jpg", "jpeg"])

    if uploaded_file is not None:
        # âœ… ì—…ë¡œë“œëœ ì´ë¯¸ì§€ ì½ê¸°
        file_bytes = np.asarray(bytearray(uploaded_file.read()), dtype=np.uint8)
        image = cv2.imdecode(file_bytes, 1)
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        
        # âœ… ì›ë³¸ ì´ë¯¸ì§€ ì¶œë ¥
        st.image(image, caption="ðŸ“· ì—…ë¡œë“œëœ ì´ë¯¸ì§€", use_container_width=True)
        
        if st.button("ðŸ”Ž íƒì§€ ì‹¤í–‰"):
            with st.spinner("ëª¨ë¸ ì‹¤í–‰ ì¤‘... â³"):
                result_image = ensemble_predictions(image)
                
                # âœ… ê²°ê³¼ ì´ë¯¸ì§€ í‘œì‹œ
                st.image(result_image, caption="ðŸ” íƒì§€ ê²°ê³¼", use_container_width=True)
                
                # âœ… ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ê¸°ëŠ¥ ì¶”ê°€
                img_rgb = cv2.cvtColor(result_image, cv2.COLOR_RGB2BGR)
                is_success, buffer = cv2.imencode(".jpg", img_rgb)
                if is_success:
                    st.download_button(
                        label="ðŸ“¥ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ",
                        data=BytesIO(buffer.tobytes()),
                        file_name="detection_result.jpg",
                        mime="image/jpeg"
                    )

if __name__ == "__main__":
    main()
