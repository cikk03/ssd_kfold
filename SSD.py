import torch
import torchvision.ops as ops
from torchvision.models.detection import ssd300_vgg16
import cv2
import numpy as np
import streamlit as st
from io import BytesIO
import json

####################################
# ëª¨ë¸ ì •ì˜ ë° ë¡œë”© í•¨ìˆ˜
####################################
def get_ssd_model(num_classes):
    model = ssd300_vgg16(pretrained=False)
    model.head.classification_head.num_classes = num_classes
    return model

device = torch.device("cpu")
st.write(f"Using device: {device}")

def load_model(path, num_classes=6):
    model = get_ssd_model(num_classes).to(device)
    model.load_state_dict(torch.load(path, map_location=device))
    model.eval()
    return model

@st.cache_resource(show_spinner=False)
def get_model():
    return load_model("best_model_ssd.pth", num_classes=6)

####################################
# ì´ë¯¸ì§€ ì „ì²˜ë¦¬ í•¨ìˆ˜
####################################
def preprocess_image_from_array(image):
    image_resized = cv2.resize(image, (300, 300))
    image_normalized = image_resized / 255.0
    image_transposed = np.transpose(image_normalized, (2, 0, 1))
    tensor = torch.tensor(image_transposed, dtype=torch.float).unsqueeze(0).to(device)
    return tensor, image

####################################
# ê°ì²´ íƒì§€ ë° ê²°ê³¼ ì‹œê°í™” í•¨ìˆ˜ (NMS ì ìš© ë° ì›ë³¸ ì´ë¯¸ì§€ ë³µì‚¬ ì‚¬ìš©)
####################################
def detect_objects(image, model, score_thr=0.5, nms_thr=0.45):
    image_tensor, orig = preprocess_image_from_array(image)
    original_image = orig.copy()
    h, w = original_image.shape[:2]

    with torch.no_grad():
        outputs = model(image_tensor)[0]

    valid_idx = (outputs['scores'] > score_thr) & (outputs['labels'] != 0)
    boxes = outputs['boxes'][valid_idx]
    scores = outputs['scores'][valid_idx]
    labels = outputs['labels'][valid_idx]

    if boxes.numel() > 0 and boxes.max() <= 1.0:
        scale_tensor = torch.tensor([w, h, w, h], device=boxes.device)
        boxes = boxes * scale_tensor
    boxes = boxes.round()

    keep_idx = ops.nms(boxes.float(), scores, nms_thr)
    boxes = boxes[keep_idx].cpu().numpy()
    scores = scores[keep_idx].cpu().numpy()
    labels = labels[keep_idx].cpu().numpy()

    # ë¼ë²¨ í…ìŠ¤íŠ¸ ë§¤í•‘
    label_mapping = {
        1: 'normal',
        2: 'Extruded',
        3: 'Crack',
        4: 'Cutting',
        5: 'Side_stamp'
    }
    # ë¼ë²¨ë³„ ìƒ‰ìƒ ë§¤í•‘ (RGB ìˆœì„œ)
    color_mapping = {
        "normal": (0, 255, 0),
        "extruded": (255, 0, 0),
        "crack": (255, 255, 0),
        "cutting": (0, 0, 255),
        "side_stamp": (255, 0, 255)
    }
    
    detection_results = []
    for box, score, label in zip(boxes, scores, labels):
        x1, y1, x2, y2 = box.astype(int)
        label_text = label_mapping.get(int(label), 'Unknown')
        # ë¼ë²¨ëª…(ì†Œë¬¸ì)ë¡œ ìƒ‰ìƒ ì§€ì •
        color = color_mapping.get(label_text.lower(), (0, 255, 0))
        # ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°
        cv2.rectangle(original_image, (x1, y1), (x2, y2), color, 2)
        
        # í…ìŠ¤íŠ¸ì™€ ë°°ê²½ ê·¸ë¦¬ê¸°
        text = f"{label_text} {score:.2f}"
        font = cv2.FONT_HERSHEY_SIMPLEX
        font_scale = 0.5
        thickness = 1
        (text_width, text_height), baseline = cv2.getTextSize(text, font, font_scale, thickness)
        # í…ìŠ¤íŠ¸ë¥¼ ë°•ìŠ¤ ìœ„ì— ë°°ì¹˜ (ì—¬ìœ ê°€ ì—†ìœ¼ë©´ ë°•ìŠ¤ ì•„ë˜ìª½ì—)
        if y1 - text_height - baseline >= 0:
            text_top = y1 - text_height - baseline
            text_bottom = y1
        else:
            text_top = y1
            text_bottom = y1 + text_height + baseline
        # í…ìŠ¤íŠ¸ ë°°ê²½ ì‚¬ê°í˜• (ì±„ì›€)
        cv2.rectangle(original_image, (x1, text_top), (x1 + text_width, text_bottom), color, thickness=-1)
        # ë¼ë²¨ í…ìŠ¤íŠ¸ë¥¼ ê²€ì •ìƒ‰ìœ¼ë¡œ ì¶œë ¥
        cv2.putText(original_image, text, (x1, text_bottom - baseline), font, font_scale, (0,0,0), thickness, cv2.LINE_AA)
        
        detection_results.append({
            "label": label_text,
            "score": float(score),
            "box": [int(x1), int(y1), int(x2), int(y2)]
        })

    return original_image, detection_results

####################################
# Streamlit UI
####################################
def main(image=None):
    st.title("ğŸ” SSD Object Detection")
    # (ê¸°ì¡´ ì„¤ëª… ë¬¸êµ¬ëŠ” ì‚­ì œ)

    if image is None:
        uploaded_file = st.file_uploader("ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”", type=["png", "jpg", "jpeg"])
        if uploaded_file is not None:
            file_bytes = np.asarray(bytearray(uploaded_file.read()), dtype=np.uint8)
            image = cv2.imdecode(file_bytes, cv2.IMREAD_COLOR)
            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            st.success(f"'{uploaded_file.name}' íŒŒì¼ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    if image is not None:
        if st.button("ğŸ” íƒì§€ ì‹¤í–‰"):
            with st.spinner("ëª¨ë¸ ì‹¤í–‰ ì¤‘..."):
                model = get_model()
                result_image, detection_results = detect_objects(image, model, score_thr=0.5, nms_thr=0.45)
            
            # ë¶ˆëŸ‰/ì •ìƒ íŒë‹¨ (ì „ì²´ë¥¼ ë‘˜ëŸ¬ì‹¼ ë°•ìŠ¤ ì™¸ì— ì¶”ê°€ ë°•ìŠ¤ê°€ ìˆìœ¼ë©´ ë¶ˆëŸ‰)
            h, w = image.shape[:2]
            tol = 0.05  # 5% ì˜¤ì°¨ í—ˆìš©

            def is_full_box(box):
                x1, y1, x2, y2 = box
                return (x1 <= tol * w and y1 <= tol * h and x2 >= (1 - tol) * w and y2 >= (1 - tol) * h)
            
            if detection_results:
                other_boxes = [d for d in detection_results if not is_full_box(d["box"])]
                if len(other_boxes) > 0:
                    st.markdown("**ë¶ˆëŸ‰ì´ ê²€ì¶œë˜ì—ˆìŠµë‹ˆë‹¤! ğŸš¨**")
                else:
                    st.markdown("**ë¶ˆëŸ‰ì´ ê²€ì¶œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤! ğŸ‰**")
            else:
                st.markdown("**íƒì§€ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤!**")
                
            st.image(result_image, caption="ğŸ” íƒì§€ ê²°ê³¼", width=550)
            
            # ê²°ê³¼ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ (JPG)
            result_bgr = cv2.cvtColor(result_image, cv2.COLOR_RGB2BGR)
            is_success, buffer = cv2.imencode(".jpg", result_bgr)
            if is_success:
                st.download_button(
                    label="ğŸ“¥ ê²°ê³¼ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ",
                    data=BytesIO(buffer.tobytes()),
                    file_name="detection_result.jpg",
                    mime="image/jpeg"
                )
            
            # JSON ê²°ê³¼ ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
            json_str = json.dumps(detection_results, indent=4, ensure_ascii=False)
            st.download_button(
                label="ğŸ“¥ ê²°ê³¼ JSON ë‹¤ìš´ë¡œë“œ",
                data=json_str,
                file_name="detection_result.json",
                mime="application/json"
            )

if __name__ == "__main__":
    main()
